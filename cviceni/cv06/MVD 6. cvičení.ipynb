{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MVD 6. cvičení\n",
    "\n",
    "## 1. část - PageRank\n",
    "\n",
    "Data k dnešnímu cvičení použijte z tohoto [Github repozitáře](https://github.com/chonyy/PageRank-HITS-SimRank/tree/master/dataset). Konkrétně nás budou zajímat soubory *graph_1.txt* až *graph_6.txt*. K daným datasetům je v repozitáři implementace PageRank algoritmu, každopádně se touto implementací nijak neinspirujte. \n",
    "\n",
    "Cílem je naprogramovat PageRank vektorizovaně podle přednášky, povoleno je pouze použití knihovny numpy. Parametr $\\alpha$ nastavte na hodnotu 0.2 a počet iterací bude 100. U prvních grafů uvidíte, že PageRank konverguje mnohem dříve a u těch složitějších nemusí stačit ani 100 iterací.\n",
    "\n",
    "<br>\n",
    "$\n",
    "p^{(0)} = (\\frac{1}{N}, ..., \\frac{1}{N})^T \\\\\n",
    "A = ((1-\\alpha)M + \\frac{\\alpha}{N}E) \\\\\n",
    "Opakujte: \\\\\n",
    "\\hspace{1cm}p^{(i+1)} = A^Tp^{(i)}\n",
    "$\n",
    "\n",
    "Pozor: Stránka, která nemá výstupní linky, musí mít nastavený parametr $\\alpha$ na 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_data = 'data/'\n",
    "paths = [path_data + 'graph_' + str(num_graph) + '.txt' for num_graph in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#load graphs\n",
    "graphs = {}\n",
    "uniq_val = {}\n",
    "for path in paths:\n",
    "    graphs[path] = {}\n",
    "    uniq_val[path] = []\n",
    "    with open(path,'r') as file:\n",
    "        for line in file:\n",
    "            parent, child = list(map(int,line.replace('\\n','').split(',')))\n",
    "            uniq_val[path].extend([child, parent])\n",
    "            if parent in graphs[path].keys():\n",
    "                graphs[path][parent].append(child)\n",
    "            else:\n",
    "                graphs[path][parent] = [child]\n",
    "    uniq_val[path] = set(uniq_val[path])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "M = {} #mat. přechodů s pravděpodobnostmi přechodu do jiného uzlu\n",
    "E = {} #jednotková / poctem uzlu\n",
    "A = {} #mat. sousednosti\n",
    "alphas = {} # alphy = O,2 default, stránky bez výstupních uzlů = 1\n",
    "alpha = 0.2\n",
    "for graph in graphs:\n",
    "    N = len(uniq_val[graph])\n",
    "    M[graph] = np.zeros((N,N))\n",
    "    A[graph] = np.zeros((N,N))\n",
    "    alphas[graph] = np.ones(N) * alpha\n",
    "    for parent in graphs[graph].keys():\n",
    "        num_child = len(graphs[graph][parent])\n",
    "        for child in graphs[graph][parent]:\n",
    "            M[graph][parent-1,child-1] = 1 / num_child\n",
    "            A[graph][parent-1,child-1] = 1\n",
    "    E[graph] = np.ones((N,N)) / N\n",
    "    alphas[graph][np.where([np.all(M[graph] == 0, axis=1)])[1]] = 1\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_iter = 100\n",
    "p = {}\n",
    "for graph in graphs:\n",
    "    N = len(uniq_val[graph])\n",
    "    p[graph] = np.ones((N,1))/N\n",
    "    for _ in range(num_iter):\n",
    "        alpha = alphas[graph][:,np.newaxis]\n",
    "        a = (1-alpha) * M[graph] + alpha * E[graph]\n",
    "        p[graph] = a.T @ p[graph]\n",
    "    print('\\033[1m' + graph + '\\033[0m')\n",
    "    print(p[graph],'\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Předpokládaný výstup\n",
    "\n",
    "#### graph_1.xt\n",
    "```python\n",
    "array([[0.0656044 ],\n",
    "       [0.11808792],\n",
    "       [0.16007474],\n",
    "       [0.19366419],\n",
    "       [0.22053575],\n",
    "       [0.242033  ]])\n",
    "```\n",
    "       \n",
    "#### graph_2.txt\n",
    "```python\n",
    "array([[0.2],\n",
    "       [0.2],\n",
    "       [0.2],\n",
    "       [0.2],\n",
    "       [0.2]])\n",
    "```\n",
    "\n",
    "\n",
    "#### graph_3.txt\n",
    "```python\n",
    "array([[0.17857143],\n",
    "       [0.32142857],\n",
    "       [0.32142857],\n",
    "       [0.17857143]])\n",
    "```\n",
    "\n",
    "\n",
    "#### graph_4.txt\n",
    "```python\n",
    "array([[0.27257372],\n",
    "       [0.15666713],\n",
    "       [0.13837881],\n",
    "       [0.10924643],\n",
    "       [0.18531604],\n",
    "       [0.06563464],\n",
    "       [0.07218322]])\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. část - HITS\n",
    "\n",
    "Použijte stejná data jako u PageRank algoritmu a počet iterací bude opět 100.\n",
    "\n",
    "Implementujte dle následujícího algoritmu:\n",
    "<br>\n",
    "\n",
    "$\n",
    "a^{(0)} = (1, ..., 1)^T, h^{(0)} = (1, ..., 1)^T\n",
    "\\\\\n",
    "Opakujte:\\\\\n",
    "    \\hspace{1cm} h^{(i+1)} = Aa^{(i)}\\\\\n",
    "    \\hspace{1cm} h^{(i+1)} = \\frac{h^{(i+1)}}{||h^{(i+1)}||_1}\\\\\n",
    "    \\hspace{1cm} a^{(i+1)} = A^Th^{(i)}\\\\\n",
    "    \\hspace{1cm} a^{(i+1)} = \\frac{a^{(i+1)}}{||a^{(i+1)}||_1}\\\\   \n",
    "$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_iter = 100\n",
    "for graph in graphs:\n",
    "    N = len(uniq_val[graph])\n",
    "    a = np.ones((N,1))\n",
    "    h = np.ones((N,1))\n",
    "    for _ in range(num_iter):\n",
    "        h_new = A[graph] @ a\n",
    "        a = A[graph].T @ h\n",
    "        h /= np.linalg.norm(h_new,1)\n",
    "        a /= np.linalg.norm(a,1)\n",
    "    print('\\033[1m' + graph + '\\033[0m')\n",
    "    print('Authority:',a)\n",
    "    print('Hub:',h,'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Předpokládaný výstup\n",
    "\n",
    "#### graph_1.xt\n",
    "```python\n",
    "Authority:[[0. ]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]]\n",
    "Hub: [[0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0. ]]\n",
    "```\n",
    "       \n",
    "#### graph_2.txt\n",
    "```python\n",
    "Authority:[[0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]]\n",
    "Hub: [[0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]]\n",
    "```\n",
    "\n",
    "\n",
    "#### graph_3.txt\n",
    "```python\n",
    "Authority:[[0.19098301]\n",
    " [0.30901699]\n",
    " [0.30901699]\n",
    " [0.19098301]]\n",
    "Hub: [[0.19098301]\n",
    " [0.30901699]\n",
    " [0.30901699]\n",
    " [0.19098301]]\n",
    "```\n",
    "\n",
    "\n",
    "#### graph_4.txt\n",
    "```python\n",
    "Authority:[[0.13948389]\n",
    " [0.17791203]\n",
    " [0.20082321]\n",
    " [0.14017775]\n",
    " [0.20142536]\n",
    " [0.05608926]\n",
    " [0.08408849]]\n",
    "Hub: [[0.27545318]\n",
    " [0.04776231]\n",
    " [0.10868324]\n",
    " [0.19865956]\n",
    " [0.1837346 ]\n",
    " [0.11673471]\n",
    " [0.06897241]]\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bonus - Invertovaný index pomocí MapReduce\n",
    "\n",
    "Bonusovou úlohou je vytvoření invertovaného indexu stejně, jako je uvedeno na příkladu v přednášce. Implementace nebude v standardním MapReduce frameworku, ale použijete python funkce ```map()``` a ```reduce()```. Funkci map lze poté spustit paralelně s pomocí ```Pool``` objektu z knihovny ```multiprocessing```. \n",
    "\n",
    "Vstupními daty budou Medium články, které jsme používali v posledních pár cvičeních. Z těchto článků použijte pouze nadpisy (title). "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from multiprocessing.pool import Pool\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    return \" \".join([token.lemma_ for token in lemmatizer(text)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/articles.csv', usecols=[\"title\", \"text\"])\n",
    "lemmatizer = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "df['title'] = df['title'].str.replace('[^\\w\\s]|','').str.replace('\\s\\s+',' ').str.lower()\n",
    "df['title'] = df['title'].apply(lemmatize_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mapping(item):\n",
    "    idx,row = item\n",
    "    words = row.split(\" \")\n",
    "    d = dict.fromkeys(set(words),0)\n",
    "    for word in set(words):\n",
    "        d[word] = (\"D\" + str(idx),words.count(word))\n",
    "    return d\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reduc(d1, d2):\n",
    "    uniq_keys = set(list(d1.keys()) + list(d2.keys()))\n",
    "    d = {}\n",
    "    for key in uniq_keys:\n",
    "        d[key] = []\n",
    "        if key in d1.keys():\n",
    "            val = [d1[key]] if type(d1[key]) == tuple else d1[key]\n",
    "            d[key] += val\n",
    "        if key in d2.keys():\n",
    "            val = [d2[key]] if type(d2[key]) == tuple else d2[key]\n",
    "            d[key] += val\n",
    "    return d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with Pool() as pool:\n",
    "    documents = list(pool.map(mapping, enumerate(df['title'].tolist(),range(10), chunksize=5)))\n",
    "inverted_index = reduce(reduc, documents)\n",
    "print(inverted_index['be'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Předpokládaný výstup\n",
    "\n",
    "```python\n",
    "print(inverted_index['be'])\n",
    "print(titles[12]) # zobrazení nadpisu pro kontrolu\n",
    "```\n",
    "```\n",
    "[('D0', 1), ('D12', 2), ('D13', 1), ('D14', 1), ('D15', 1), ('D18', 1), ('D36', 1), ('D56', 1), ('D57', 1), ('D58', 1), ('D60', 1), ('D61', 1), ('D83', 1), ('D86', 1), ('D87', 1), ('D98', 1), ('D108', 1), ('D113', 1), ('D121', 1), ('D123', 2), ('D128', 1), ('D136', 1), ('D138', 1), ('D139', 1), ('D140', 1), ('D153', 1), ('D169', 1), ('D170', 1), ('D216', 1), ('D218', 1), ('D224', 1), ('D227', 1), ('D231', 1), ('D233', 1), ('D237', 1), ('D246', 1), ('D258', 1), ('D261', 1), ('D264', 1), ('D267', 1), ('D273', 1), ('D321', 1), ('D330', 1), ('D335', 1)]\n",
    "```\n",
    "deep learning be go to teach we all the lesson of our life job be for machine\n",
    "\n",
    "Výstup bude identický za předpokladu použití spacy lemmatizéru. Zároveň výstup nemusí obsahovat stejný formát indexu, postačí *(index, count)*."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}