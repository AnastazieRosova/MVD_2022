{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVD 4. cvičení\n",
    "\n",
    "## 1. část - Načtení dat\n",
    "\n",
    "Po rozbalení archive.zip uvidíte articles csv soubor. Tento soubor pochází z [Kaggle datasetů](https://www.kaggle.com/hsankesara/medium-articles) a obsahuje malé množství Medium článků k tématům ML, AI a data science. K úloze dnešního cvičení bude stačit využítí dat s názvy a obsahy článků (title a text).\n",
    "\n",
    "\n",
    "### Příprava dat\n",
    "\n",
    "Pro přípravu dat se použivá různá sekvence kroků. Je doporučeno na následující kroky vytvořit samostatnou funkci, aby bylo možné zpracovat i vyhledávaný výraz při testování. Dnešní cvičení by mělo obsahovat následující kroky:\n",
    "\n",
    "1. Převést všechen text na lower case\n",
    "2. Odstranění interpunkce a všech speciálních znaků (apostrof, ...)\n",
    "3. Aplikace lemmatizátoru\n",
    "\n",
    "Pozn.: Jedná se pouze o jednoduchý preprocessing, v praxi je často potřeba použití více kroků. Tato aplikace by měla například problém s čísly (desetinná čísla, čísla vyhledávaná slovně). \n",
    "\n",
    "Pro lemmatizaci použijte knihovnu spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import spacy\n",
    "lemmatizer = spacy.load('en_core_web_sm', disable=['parser', 'ner']) # NLTK\n",
    "# Lemmatizace textu př.:  \n",
    "# \" \".join([token.lemma_ for token in lemmatizer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    return \" \".join([token.lemma_ for token in lemmatizer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('articles.csv', usecols=[\"title\", \"text\"])\n",
    "\n",
    "df['title'] = df['title'].str.replace('[^\\w\\s]','').str.lower()\n",
    "df['text'] = df['text'].str.replace('[^\\w\\s]','').str.lower()\n",
    "df['text'] = df['text'].str.replace('\\s\\s+',' ')\n",
    "df['title'] = df['title'].str.replace('\\s\\s+',' ')\n",
    "\n",
    "df['title'] = df['title'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace spaCy z Jupyter Notebooku\n",
    "#!{sys.executable} -m pip install spacy\n",
    "\n",
    "# Stažení modelu pro angličtinu\n",
    "#!{sys.executable} -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. část - Vytvoření invertovaného indexu\n",
    "\n",
    "Před další prací s textem je potřeba vytvořit invertovaný index, který poté usnadní práci. Invertovaný index bude slovník, kde klíčem bude slovo a hodnotou bude list s id dokumentů (index), které dané slovo obsahují.\n",
    "\n",
    "Pozn.: Je potřeba vytvořit dva invertované indexy - jeden pro title a druhý pro text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(document):\n",
    "    dic = {}\n",
    "    for id_doc, row in enumerate(document):\n",
    "        words = row.split(\" \")\n",
    "        for idx_word, word in enumerate(words):\n",
    "            if word in dic.keys():\n",
    "                if id_doc in dic[word]:\n",
    "                    continue\n",
    "                dic[word].append(id_doc)\n",
    "            else:\n",
    "                dic[word] = [id_doc]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_title = inverted_index(df['title'].tolist())\n",
    "inv_text = inverted_index(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. část - Implementace TF-IDF\n",
    "\n",
    "Připravení funkce pro výpočet TF-IDF po příchodu dotazu. Funkce *tf_idf* by měla pracovat s dotazem, jedním invertovaným indexem a s danými dokumenty. Vrátit by měla list obsahující skóre pro každý dokument.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "$\n",
    "score(q,d) = TF\\_IDF(q,d) = \\sum\\limits_{w \\in q \\cap d} c(w, q) c(w, d) log(\\frac{M+1}{df(w)})\n",
    "$\n",
    "</center>\n",
    "\n",
    "$q$ ... dotaz<br>\n",
    "$d$ ... dokument<br>\n",
    "$c(w, q)$ ... kolikrát je slovo *w* v dotazu *q*<br>\n",
    "$M$ ... celkový počet dokumentů<br>\n",
    "$df(w)$ ... počet dokumentů, ve kterých se nachází slovo *w*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(querry,documents,df):\n",
    "    scores = {}\n",
    "    M = len(documents)\n",
    "    words = querry.split(\" \")\n",
    "    c_wq = [words.count(w) for w in words]\n",
    "    for idx_d,d in enumerate(documents.tolist()):\n",
    "        score = 0\n",
    "        for idx_q, word in enumerate(words):\n",
    "            score += c_wq[idx_q] * d.count(word) * math.log((M+1)/len(df[word]))\n",
    "        scores[idx_d] = score\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = tf_idf(\"coursera vs udacity machine learning\", df['title'],inv_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. část - Použití a testování TF-IDF\n",
    "\n",
    "Nyní lze získat skóre pro titulky nebo text. Následujícím krokem je sjednocení výsledného skóre pro ohodnocení celého dokumentu. V případě dvou hodnot si vystačíme s parametrem $\\alpha$, který nám určuje jakou váhu má titulek a jakou samotný text dokumentu. <br>\n",
    "\n",
    "<center>\n",
    "$\n",
    "score(q,d) = \\alpha \\; TF\\_IDF\\_title(q,d) + (1-\\alpha) \\; TF\\_IDF\\_text(q,d)\n",
    "$\n",
    "</center>\n",
    "\n",
    "Při nastavení parametru $\\alpha$ na hodnotu 0.7 a vyhledávání dotazu \"coursera vs udacity machine learning\" by výsledky měly vypadat následovně:\n",
    "\n",
    "![output](sample_output.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>coursera vs udacity for machine learning hacke...</td>\n",
       "      <td>2018 be an exciting time for student of machin...</td>\n",
       "      <td>43.081344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>every single machine learning course on the in...</td>\n",
       "      <td>a year and a half ago I drop out of one of the...</td>\n",
       "      <td>33.907372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>every single machine learning course on the in...</td>\n",
       "      <td>a year and a half ago I drop out of one of the...</td>\n",
       "      <td>33.907372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>every single machine learning course on the in...</td>\n",
       "      <td>a year and a half ago I drop out of one of the...</td>\n",
       "      <td>33.907372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>every single machine learning course on the in...</td>\n",
       "      <td>a year and a half ago I drop out of one of the...</td>\n",
       "      <td>33.907372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>what be the good intelligent chatbot or ai cha...</td>\n",
       "      <td>how do we define the intelligence of a chatbot...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>selfdrive car and the trolley problem tanay ja...</td>\n",
       "      <td>google recently announce that their selfdrive ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>build a smart home feed pinter engineering medium</td>\n",
       "      <td>chris pinchak pinter engineer discovery \\n the...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>the evolve role of business analytic frank dia...</td>\n",
       "      <td>an old post that seem to be get a lot of atten...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>c plays bejewel blitz idanscott medium</td>\n",
       "      <td>as some of you read this may or may not alread...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "276  coursera vs udacity for machine learning hacke...   \n",
       "19   every single machine learning course on the in...   \n",
       "67   every single machine learning course on the in...   \n",
       "99   every single machine learning course on the in...   \n",
       "143  every single machine learning course on the in...   \n",
       "..                                                 ...   \n",
       "267  what be the good intelligent chatbot or ai cha...   \n",
       "130  selfdrive car and the trolley problem tanay ja...   \n",
       "40   build a smart home feed pinter engineering medium   \n",
       "105  the evolve role of business analytic frank dia...   \n",
       "245             c plays bejewel blitz idanscott medium   \n",
       "\n",
       "                                                  text     scores  \n",
       "276  2018 be an exciting time for student of machin...  43.081344  \n",
       "19   a year and a half ago I drop out of one of the...  33.907372  \n",
       "67   a year and a half ago I drop out of one of the...  33.907372  \n",
       "99   a year and a half ago I drop out of one of the...  33.907372  \n",
       "143  a year and a half ago I drop out of one of the...  33.907372  \n",
       "..                                                 ...        ...  \n",
       "267  how do we define the intelligence of a chatbot...        0.0  \n",
       "130  google recently announce that their selfdrive ...        0.0  \n",
       "40   chris pinchak pinter engineer discovery \\n the...        0.0  \n",
       "105  an old post that seem to be get a lot of atten...        0.0  \n",
       "245  as some of you read this may or may not alread...        0.0  \n",
       "\n",
       "[337 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.7\n",
    "querry = \"coursera vs udacity machine learning\"\n",
    "scores_title = tf_idf(querry, df['title'],inv_title)\n",
    "scores_text = tf_idf(querry, df['text'],inv_text)\n",
    "scores = {}\n",
    "df['scores'] = None\n",
    "for idx, row in df.iterrows():\n",
    "    df['scores'][idx]=alpha*scores_title[idx]+(1-alpha)*scores_text[idx]\n",
    "df.sort_values('scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
