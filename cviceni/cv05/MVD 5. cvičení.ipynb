{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVD 5. cvičení\n",
    "\n",
    "## 1. část - TF-IDF s word embeddingy\n",
    "\n",
    "V minulém cvičení bylo za úkol implementovat TF-IDF algoritmus nad datasetem z Kagglu. Dnešní cvičení je rozšířením této úlohy s použitím word embeddingů. Lze použít předtrénované GloVe embeddingy ze 3. cvičení, nebo si v případě zájmu můžete vyzkoušet práci s Word2Vec od Googlu (najdete [zde](https://code.google.com/archive/p/word2vec/)).\n",
    "\n",
    "Cvičení by mělo obsahovat následující části:\n",
    "- Načtení článků a embeddingů\n",
    "- Výpočet document vektorů pomocí TF-IDF a word embeddingů \n",
    "    - Pro výpočet TF-IDF využijte [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) z knihovny sklearn\n",
    "    - Vážený průměr GloVe / Word2Vec vektorů\n",
    "\n",
    "<center>\n",
    "$\n",
    "doc\\_vector = \\frac{1}{|d|} \\sum\\limits_{w \\in d} TF\\_IDF(w) glove(w)\n",
    "$\n",
    "</center>\n",
    "\n",
    "- Dotaz bude transformován stejně jako dokument\n",
    "\n",
    "- Výpočet relevance pomocí kosinové podobnosti\n",
    "<center>\n",
    "$\n",
    "score(q,d) = cos\\_sim(query\\_vector, doc\\_vector)\n",
    "$\n",
    "</center>\n",
    "\n",
    "### Načtení článků"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "from numpy.linalg import norm\n",
    "from numpy import dot\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('articles.csv', usecols=[\"title\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    return \" \".join([token.lemma_ for token in lemmatizer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatbots be the next big thing what happen the...</td>\n",
       "      <td>oh how the headline blare \\n chatbot be the ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>python for data science 8 concept you may have...</td>\n",
       "      <td>if you ve ever find yourself look up the same ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>automate feature engineering in python towards...</td>\n",
       "      <td>machine learning be increasingly move from han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>machine learn how to go from zero to hero free...</td>\n",
       "      <td>if your understanding of ai and machine learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reinforcement learning from scratch insight datum</td>\n",
       "      <td>want to learn about apply artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>you can build a neural network in javascript e...</td>\n",
       "      <td>click here to share this article on linkedin s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>artificial intelligence ai in 2018 and beyond ...</td>\n",
       "      <td>these be my opinion on where deep neural netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>spike neural network the next generation of ma...</td>\n",
       "      <td>everyone who have be remotely tune in to recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>surprise neuron be now more complex than we think</td>\n",
       "      <td>one of the big misconception around be the ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>wth do a neural network even learn a newcomer ...</td>\n",
       "      <td>I believe we all have that psychologistphiloso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    chatbots be the next big thing what happen the...   \n",
       "1    python for data science 8 concept you may have...   \n",
       "2    automate feature engineering in python towards...   \n",
       "3    machine learn how to go from zero to hero free...   \n",
       "4    reinforcement learning from scratch insight datum   \n",
       "..                                                 ...   \n",
       "332  you can build a neural network in javascript e...   \n",
       "333  artificial intelligence ai in 2018 and beyond ...   \n",
       "334  spike neural network the next generation of ma...   \n",
       "335  surprise neuron be now more complex than we think   \n",
       "336  wth do a neural network even learn a newcomer ...   \n",
       "\n",
       "                                                  text  \n",
       "0    oh how the headline blare \\n chatbot be the ne...  \n",
       "1    if you ve ever find yourself look up the same ...  \n",
       "2    machine learning be increasingly move from han...  \n",
       "3    if your understanding of ai and machine learni...  \n",
       "4    want to learn about apply artificial intellige...  \n",
       "..                                                 ...  \n",
       "332  click here to share this article on linkedin s...  \n",
       "333  these be my opinion on where deep neural netwo...  \n",
       "334  everyone who have be remotely tune in to recen...  \n",
       "335  one of the big misconception around be the ide...  \n",
       "336  I believe we all have that psychologistphiloso...  \n",
       "\n",
       "[337 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['title'] = df['title'].str.replace('[^\\w\\s]','').str.lower()\n",
    "df['text'] = df['text'].str.replace('[^\\w\\s]','').str.lower()\n",
    "df['text'] = df['text'].str.replace('\\s\\s+',' ')\n",
    "df['title'] = df['title'].str.replace('\\s\\s+',' ')\n",
    "\n",
    "df['title'] = df['title'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(document):\n",
    "    dic = {}\n",
    "    for id_doc, row in enumerate(document):\n",
    "        words = row.split(\" \")\n",
    "        for idx_word, word in enumerate(words):\n",
    "            if word in dic.keys():\n",
    "                if id_doc in dic[word]:\n",
    "                    continue\n",
    "                dic[word].append(id_doc)\n",
    "            else:\n",
    "                dic[word] = [id_doc]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Načtení embeddingů"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_words = []\n",
    "glove_vectors = []\n",
    "glove_word2idx = {}\n",
    "file = ['glove/glove.6B.50d.txt','glove/glove.6B.100d.txt','glove/glove.6B.200d.txt','glove/glove.6B.300d.txt']\n",
    "with open(file[0]) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        row = line.split(\" \")\n",
    "        glove_words.append(row[0])\n",
    "        glove_vectors.append([float(num) for num in row[1:len(row)-1]])\n",
    "        glove_vectors[-1].extend([float(row[len(row)-1].replace('\\n',''))])     \n",
    "        glove_word2idx[row[0]]=idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + Word2Vec a vytvoření doc vektorů"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(word, count, inv_idx, M):\n",
    "    return count * math.log((M+1)/len(inv_idx[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_word2vec(df, glove_word2idx, glove_vectors, inv_idx):\n",
    "    vectors = np.zeros((len(df),len(glove_vectors[0])))\n",
    "    for idx_d,text in enumerate(df.tolist()):\n",
    "        words = text.split(\" \")\n",
    "        for word in words:\n",
    "            if word in glove_word2idx.keys():\n",
    "                vectors[idx_d,:] += (np.array(glove_vectors[glove_word2idx[word]]) * tf_idf(word, words.count(word), inv_idx, len(df)))                          \n",
    "        vectors[idx_d,:] /= len(words)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformace dotazu a výpočet relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vec_querry, vec2):\n",
    "    score = np.zeros(vec2.shape[0])\n",
    "    for i in range(vec2.shape[0]):\n",
    "        score[i] = np.abs(dot(vec_querry, vec2[i,:]))/(norm(vec_querry) * norm(vec2[i,:]))\n",
    "    return score\n",
    "    #return dot(vec_querry, np.transpose(vec2))/(norm(vec_querry)*norm(vec2,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>a beginner guide to aiml machine learning for ...</td>\n",
       "      <td>part 1 why machine learning matter the big pic...</td>\n",
       "      <td>0.834309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>a beginner guide to aiml machine learning for ...</td>\n",
       "      <td>part 1 why machine learning matter the big pic...</td>\n",
       "      <td>0.834309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>a beginner guide to aiml machine learning for ...</td>\n",
       "      <td>part 1 why machine learning matter the big pic...</td>\n",
       "      <td>0.834309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>learn how to code neural network learn new stu...</td>\n",
       "      <td>this be the second post in a series of I try t...</td>\n",
       "      <td>0.824249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>machine learning be fun part 3 deep learning a...</td>\n",
       "      <td>update this article be part of a series check ...</td>\n",
       "      <td>0.822888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>announce poncho the weatherbot renderfrombetawork</td>\n",
       "      <td>you can now get personal weather forecast in s...</td>\n",
       "      <td>0.274610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>o grupo de estudo em deep learning de brasilia...</td>\n",
       "      <td>o grupo de estudo em deep learning de brasilia...</td>\n",
       "      <td>0.203857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>de la cooperation entre les homme et les machi...</td>\n",
       "      <td>originally publish at wwwcuberevuecom on novem...</td>\n",
       "      <td>0.186547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>semantica desde informacion desestructurada be...</td>\n",
       "      <td>detectar patrone es un nucleo importante en el...</td>\n",
       "      <td>0.154085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>建议的程序员学习lda算法的步骤 蒸汽与魔法</td>\n",
       "      <td>这一阵为了工作上的关系花了点时间学习了一下lda算法说实话对于我这个学cs而非学数学的人来说...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "144  a beginner guide to aiml machine learning for ...   \n",
       "68   a beginner guide to aiml machine learning for ...   \n",
       "196  a beginner guide to aiml machine learning for ...   \n",
       "312  learn how to code neural network learn new stu...   \n",
       "169  machine learning be fun part 3 deep learning a...   \n",
       "..                                                 ...   \n",
       "242  announce poncho the weatherbot renderfrombetawork   \n",
       "167  o grupo de estudo em deep learning de brasilia...   \n",
       "234  de la cooperation entre les homme et les machi...   \n",
       "307  semantica desde informacion desestructurada be...   \n",
       "23                              建议的程序员学习lda算法的步骤 蒸汽与魔法   \n",
       "\n",
       "                                                  text     score  \n",
       "144  part 1 why machine learning matter the big pic...  0.834309  \n",
       "68   part 1 why machine learning matter the big pic...  0.834309  \n",
       "196  part 1 why machine learning matter the big pic...  0.834309  \n",
       "312  this be the second post in a series of I try t...  0.824249  \n",
       "169  update this article be part of a series check ...  0.822888  \n",
       "..                                                 ...       ...  \n",
       "242  you can now get personal weather forecast in s...  0.274610  \n",
       "167  o grupo de estudo em deep learning de brasilia...  0.203857  \n",
       "234  originally publish at wwwcuberevuecom on novem...  0.186547  \n",
       "307  detectar patrone es un nucleo importante en el...  0.154085  \n",
       "23   这一阵为了工作上的关系花了点时间学习了一下lda算法说实话对于我这个学cs而非学数学的人来说...       NaN  \n",
       "\n",
       "[337 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#inv_title = inverted_index(df['title'].tolist())\n",
    "#inv_text = inverted_index(df['text'].tolist())\n",
    "\n",
    "\n",
    "vectors_title = tf_idf_word2vec(df['title'], glove_word2idx,glove_vectors, inv_title)\n",
    "vectors_text = tf_idf_word2vec(df['text'], glove_word2idx,glove_vectors, inv_text)\n",
    "querry = \"coursera vs udacity machine learning\"\n",
    "\n",
    "df_querry = pd.DataFrame([querry], columns=['querry'])\n",
    "df_querry['querry'] = df_querry['querry'].apply(lemmatize_text)\n",
    "\n",
    "querry_vec_title = tf_idf_word2vec(df_querry['querry'], glove_word2idx, glove_vectors, inv_title)\n",
    "querry_vec_text = tf_idf_word2vec(df_querry['querry'], glove_word2idx, glove_vectors, inv_text)\n",
    "alpha = 0.7\n",
    "df['score'] = np.squeeze(alpha*cos_sim(querry_vec_title,vectors_title) + (1-alpha)*cos_sim(querry_vec_text,vectors_text))\n",
    "df = df.sort_values(by=['score'], ascending=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
